# Copyright 2025 Canonical Ltd.
# See LICENSE file for licensing details.

name: Run tests (on input)
description: Run integration test with given parameters

inputs:
  tox-env:
    description: "The name of tox environment to run for tests"
    required: true
  spark-version:
    description: "The version of Spark to run the tests on"
    default: 3.4.4
    required: false
    type: string
  bundle-backend:
    description: "The backend to use to deploy the bundle"
    default: yaml
    required: false
    type: string
  storage-backend:
    description: "The object storage backend to be used"
    default: s3
    required: false
    type: string
  cos-model:
    description: "The name of the model to deploy COS bundle"
    default:
    required: false
    type: string
  juju-snap-channel:
    description: "The channel from which juju snap is to be downloaded"
    required: false
    default: 3.6/stable
    type: string
  juju-agent-version:
    description: "The version of the Juju agent to be used"
    required: false
    default: 3.6.8
    type: string
  azure-storage-account:
    description: "The Azure Storage account name to be used for test"
    required: false
    default: "dummy-account"
    type: string
  azure-storage-key:
    description: "The Azure Storage account secret key to be used for test"
    required: false
    default: "dummy-key"
    type: string
  pytest-args:
    description: "Extra arguments to be passed to pytest command"
    required: false
    default: ""
    type: string

runs:
  using: "composite"
  steps:
    - name: Checkout repository
      uses: actions/checkout@v5

    - name: Install pipx
      shell: bash
      run: |
        sudo apt-get install -yqq pipx
        pipx ensurepath
        sudo pipx ensurepath

    - name: Disk usage
      shell: bash
      run: |
        sudo rm -rf \
          /opt/google \
          /opt/hostedtoolcache \
          /opt/microsoft/powershell \
          /opt/microsoft/msedge \
          "$AGENT_TOOLSDIRECTORY" \
          /usr/lib/firefox \
          /usr/lib/mono \
          /usr/local/julia* \
          /usr/local/lib/android \
          /usr/local/share/chromium \
          /usr/local/share/powershell \
          /usr/share/dotnet \
          /usr/share/gradle* \
          /usr/share/miniconda \
          /usr/share/sbt \
          /usr/share/swift \
          /home/linuxbrew
        pipx uninstall-all
        printf '\nDisk usage\n'
        df --human-readable

    - name: Install tox & poetry
      shell: bash
      run: |
        pipx install tox
        pipx install poetry

    - name: Setup environment
      shell: bash
      run: |
        # Avoiding dockerhub rate limits (see https://canonical-self-hosted-github-runner-docs.readthedocs-hosted.com/en/latest/usage/faq/how-to-avoid-dockerhub-rate-limits/ for more informations)
        if [ -n "$DOCKERHUB_MIRROR" ]; then
        MIRROR_CONFIG=/etc/containerd/hosts.d/docker.io
        
        sudo mkdir -p ${MIRROR_CONFIG}
        sudo chown $USER ${MIRROR_CONFIG}
        cat << EOF > ${MIRROR_CONFIG}/hosts.toml
        [host."$DOCKERHUB_MIRROR"]
        capabilities = ["pull", "resolve"]
        EOF
        fi
        
        sudo apt-get remove -y docker.io containerd
        sudo rm -rf /run/containerd /var/lib/docker /var/lib/containerd
        
        sudo snap install concierge --classic
        cd .github
        
        # Set the K8s version
        yq -i e '.providers.k8s.channel = "1.32-classic/stable"' concierge.yaml
        
        # Set the versions
        # yq -i e '.providers.k8s.channel = "${{ env.K8S_VERSION }}-classic/stable"' concierge.yaml
        yq -i e '.juju.channel = "${{ inputs.juju-snap-channel }}"' concierge.yaml
        yq -i e '.juju.agent-version = "${{ inputs.juju-agent-version }}"' concierge.yaml
        
        sudo concierge prepare --trace
        cd ..

    - id: setup-python
      name: Setup Python
      uses: actions/setup-python@v5.0.0
      with:
        python-version: "3.10"
        architecture: x64

    - name: Setup spark object storage
      id: spark-object-storage
      if: ${{ inputs.storage-backend == 's3' }}
      shell: bash
      env:
        CLOUD_INIT_FILE: |
          #cloud-config
          package_upgrade: true
          snap:
            commands:
              0: snap install microceph
              1: sudo microceph cluster bootstrap
              2: sudo microceph disk add loop,1G,3
              3: sudo microceph enable rgw
              4: sudo microceph.radosgw-admin user create --uid test --display-name test --access-key=foo --secret-key=bar

      run: |
        echo -e "$CLOUD_INIT_FILE" > microceph_rgw.yaml
        lxc init ubuntu:jammy ceph -c limits.cpu=4 -c limits.memory=2GB -d root,size=5GB
        
        lxc config set ceph cloud-init.user-data - < microceph_rgw.yaml
        lxc start ceph
        while ! lxc exec ceph -- id -u ubuntu &>/dev/null; do sleep 0.5; done
        lxc exec ceph -- cloud-init status --wait
        
        echo -e "S3_SERVER_URL=http://$(lxc list --format json | yq '.[] | select(.name == "ceph") .state.network.eth0.addresses.[] | select(.family == "inet") .address'):80/\nS3_ACCESS_KEY=foo\nS3_SECRET_KEY=bar" > .env
        lxc list
        cat .env

    - name: Select tests
      id: select-tests
      shell: bash
      run: |
        if [ "${{ github.event_name }}" == "schedule" ]
        then
          echo Running unstable and stable tests
          echo "mark_expression=" >> $GITHUB_OUTPUT
        else
          echo Skipping unstable tests
          echo "mark_expression=not unstable" >> $GITHUB_OUTPUT
        fi

    - id: setup-terraform
      name: Install terraform if needed
      shell: bash
      run: |
        if ! [ -x "$(command -v terraform)" ]; then
          echo "Installing terraform from snap"
          sudo snap install terraform --classic
        fi

    - id: tests-integration
      name: Run Integration Tests
      shell: bash
      env:
        AZURE_STORAGE_ACCOUNT: ${{ inputs.azure-storage-account }}
        AZURE_STORAGE_KEY: ${{ inputs.azure-storage-key }}
      run: |
        juju add-model spark-bundle-test
        juju list-models
        cd python && tox run -e ${{ inputs.tox-env }} -- -m '${{ steps.select-tests.outputs.mark_expression }}' --backend ${{ inputs.bundle-backend }} --cos-model ${{ inputs.cos-model }} --spark-version ${{ inputs.spark-version }} --storage-backend ${{ inputs.storage-backend }} --model spark-bundle-test ${{ inputs.pytest-args }}
        echo "TEST_EXIT_CODE=$?" >> $GITHUB_ENV

    - id: collect-logs
      name: Collect logs if job failed
      shell: bash
      if: ${{ failure() }}
      run: |
        juju-crashdump --model spark-bundle-test
        if [[ -n "${{ inputs.cos-model }}" ]]; then
          juju-crashdump --model "${{ inputs.cos-model }}"
        fi

    - id: debug-info
      name: Debug info
      shell: bash
      if: ${{ failure() }}
      run: |
        printf '\nDisk usage after tests\n'
        df --human-readable
        
        printf '\nJuju status(es)\n'
        juju status -m spark-bundle-test
        if [[ -n "${{ inputs.cos-model }}" ]]; then
          printf '\nCos status\n'
          juju status -m cos
        fi
        
        printf '\nK8s pods\n'
        kubectl get pods -n spark-bundle-test -o wide
        if [[ -n "${{ inputs.cos-model }}" ]]; then
          printf '\nCos pods\n'
          kubectl get pods -n cos -o wide
        fi
        
        printf '\nK8s events\n'
        kubectl get events -n spark-bundle-test -o wide
        if [[ -n "${{ inputs.cos-model }}" ]]; then
          printf '\nCos events\n'
          kubectl get events -n cos -o wide
        fi
        
        printf '\nDebug logs\n'
        juju debug-log -m spark-bundle-test --replay -l INFO | tail -n 500
        if [[ -n "${{ inputs.cos-model }}" ]]; then
          printf '\nCos logs\n'
          juju debug-log -m cos --replay -l INFO | tail -n 500
        fi

    - name: Write test result in JSON format
      shell: bash
      if: always()
      run: |
        STATUS="success"
        if [ "${TEST_EXIT_CODE}" != "0" ]; then
          STATUS="failure"
        fi
        echo '{"tox-env": "${{ inputs.tox-env }}", "spark-version": "${{ inputs.spark-version }}", "bundle-backend": "${{ inputs.bundle-backend }}", "storage-backend": "${{ inputs.storage-backend }}", "cos": "${{ inputs.cos-model != '' }}", "juju-version": "${{ inputs.juju-agent-version }}", "status": "'"$STATUS"'"}' > test-result.json

    - name: Upload the test result as artifact
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: integration-results-${{ inputs.tox-env }}-${{ inputs.spark-version }}-${{ inputs.bundle-backend }}-${{ inputs.storage-backend }}-${{ inputs.cos-model }}-${{ inputs.juju-agent-version }}
        path: test-result.json


