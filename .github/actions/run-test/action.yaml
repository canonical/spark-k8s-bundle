# Copyright 2025 Canonical Ltd.
# See LICENSE file for licensing details.

name: Run tests (on input)
description: Run integration test with given parameters

inputs:
  tox-env:
    description: "The name of tox environment to run for tests"
    required: true
  spark-version:
    description: "The version of Spark to run the tests on"
    default: 3.4.2
    required: false
    type: string
  bundle-backend:
    description: "The backend to use to deploy the bundle"
    default: yaml
    required: false
    type: string
  storage-backend:
    description: "The object storage backend to be used"
    default: s3
    required: false
    type: string
  cos-model:
    description: "The name of the model to deploy COS bundle"
    default:
    required: false
    type: string
  juju-snap-channel:
    description: "The channel from which juju snap is to be downloaded"
    required: false
    default: 3.6/stable
    type: string
  juju-agent-version:
    description: "The version of the Juju agent to be used"
    required: false
    default: 3.6.0
    type: string
  azure-storage-account:
    description: "The Azure Storage account name to be used for test"
    required: false
    default: "dummy-account"
    type: string
  azure-storage-key:
    description: "The Azure Storage account secret key to be used for test"
    required: false
    default: "dummy-key"
    type: string

runs:
  using: "composite"
  steps:
    - name: (GitHub hosted) Free up disk space
      shell: bash
      run: |
        printf '\nDisk usage before cleanup\n'
        df --human-readable
        # Based on https://github.com/actions/runner-images/issues/2840#issuecomment-790492173
        rm -r /usr/share/dotnet
        rm -r /opt/hostedtoolcache/
        printf '\nDisk usage after cleanup\n'
        df --human-readable
    - name: Checkout repo
      uses: actions/checkout@v4
    - id: setup-python
      name: Setup Python
      uses: actions/setup-python@v5.0.0
      with:
        python-version: "3.10"
        architecture: x64
    - name: Setup operator environment
      uses: charmed-kubernetes/actions-operator@main
      with:
        juju-channel: ${{ inputs.juju-snap-channel }}
        provider: microk8s
        channel: 1.32-strict/stable
        bootstrap-options: "--agent-version ${{ inputs.juju-agent-version }}"
        microk8s-group: snap_microk8s
        microk8s-addons: "rbac dns minio metallb:10.64.140.43-10.64.140.49"
    - name: Install tox & poetry
      shell: bash
      run: |
        pip install tox
        pip install poetry
    - name: Select tests
      id: select-tests
      shell: bash
      run: |
        if [ "${{ github.event_name }}" == "schedule" ]
        then
          echo Running unstable and stable tests
          echo "mark_expression=" >> $GITHUB_OUTPUT
        else
          echo Skipping unstable tests
          echo "mark_expression=not unstable" >> $GITHUB_OUTPUT
        fi
    - id: setup-terraform
      name: Install terraform if needed
      shell: bash
      run: |
        if ! [ -x "$(command -v terraform)" ]; then
          echo "Installing terraform from snap"
          sudo snap install terraform --classic
        fi
    - id: cache-image
      name: Cache Image Locally
      shell: bash
      run: |
        # Download image for avoiding time out
        IMAGE="ghcr.io/canonical/charmed-spark-kyuubi@sha256:9268d19a6eef91914e874734b320fab64908faf0f7adb8856be809bc60ecd1d0"

        docker pull $IMAGE
        docker save $IMAGE -o image.tar
        sudo microk8s ctr images import --base-name $IMAGE image.tar
        docker rmi $IMAGE
        rm image.tar
    - id: tests-integration
      name: Run Integration Tests
      shell: bash
      env:
        AZURE_STORAGE_ACCOUNT: ${{ inputs.azure-storage-account }}
        AZURE_STORAGE_KEY: ${{ inputs.azure-storage-key }}
      run: |
        juju list-models
        cd python && tox run -e ${{ inputs.tox-env }} -- -m '${{ steps.select-tests.outputs.mark_expression }}' --backend ${{ inputs.bundle-backend }} --cos-model ${{ inputs.cos-model }} --spark-version ${{ inputs.spark-version }} --storage-backend ${{ inputs.storage-backend }} --keep-models
